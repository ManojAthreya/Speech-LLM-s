{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "OPEN AI WHISPER MODEL INFERENCE"
      ],
      "metadata": {
        "id": "0mZaAVoIFBO5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Libraries and Packages"
      ],
      "metadata": {
        "id": "pNyj5QdjFJrd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZXmgdgXBoMv"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate datasets[audio]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "8lxkZRZwCqVm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32"
      ],
      "metadata": {
        "id": "DF4wjC4YCkrL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Loading"
      ],
      "metadata": {
        "id": "Ht6nYH2AFO3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"openai/whisper-large-v3\"\n",
        "\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y49SLbM7Cvri",
        "outputId": "78bca170-1766-4417-cd99-bcb2d7dee066"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Loading"
      ],
      "metadata": {
        "id": "syYcVY6wFRi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
        "sample = dataset[0][\"audio\"]"
      ],
      "metadata": {
        "id": "AgTVjA37E9Av"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference using pipeline from Huggingface ü§ó\n",
        "Transcribing (Audio -> Text)"
      ],
      "metadata": {
        "id": "m9e-qcO_FTsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=model,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    max_new_tokens=128,\n",
        "    chunk_length_s=30,\n",
        "    batch_size=16,\n",
        "    return_timestamps=True,\n",
        "    torch_dtype=torch_dtype,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "result = pipe(sample)\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgFRCOqyC1lZ",
        "outputId": "6dc27da5-3983-466c-e11e-53d423dc5974"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Leighton's work is really Greek after all, and can discover in it but little of rocky Ithaca. Lynyll's pictures are a sort of Upgards and Adam paintings, and Mason's exquisite idylls are as national as a django poem. Mr. Burkett Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth. And Mr. John Collier gives his sitter a cheerful slap on the back before he says, like a shampooer in a Turkish bath, Next, man!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Own Dataset Audio file or get audio file from youtube"
      ],
      "metadata": {
        "id": "rzpvW0A-Ff6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vwHL17zyGTGM",
        "outputId": "b10e379c-6484-4b88-88de-20bd16023378"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'en_US.UTF-8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnphaevvDKbT",
        "outputId": "a89ca5f1-fa78-4d20-8ebd-209cebf3f6cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading audio from youtube"
      ],
      "metadata": {
        "id": "LoshQJr1Mata"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Pytube library\n",
        "import pytube\n",
        "# Reading the above Taken movie Youtube link\n",
        "video = \"https://youtube.com/shorts/-9Vc2zo3mIE?si=8qlBFPC2AaEg_JNL\"\n",
        "data = pytube.YouTube(video)\n",
        "# Converting and downloading as 'MP4' file\n",
        "audio = data.streams.get_audio_only()\n",
        "audio.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qdPuJH4WFzEs",
        "outputId": "b8e8fec2-f3a8-4632-b420-a3ed1dd2b71b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Elon Musk Advice to Young People - Lex Fridman Podcast.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Pipe function to convert audio file to text"
      ],
      "metadata": {
        "id": "n3nb9ttZMfAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe(\"audio3.mp4\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0UeoUY6FzLH",
        "outputId": "f82ebedd-451a-4cf6-a90e-a6d823ad4cc2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " If you wanna run away with me, I know a galaxy and I can take you for a ride I had a premonition that we fell into a rhythm where the music don't stop for life Glitter in the sky, glitter in my eyes, shining just the way you like If you're feeling like you need a little bit of company, you met me at the perfect time You want me, I want you baby, my sugar boo, I'm levitating The Milky Way, we're renegading, yeah, yeah, yeah, yeah, yeah\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can specify the language as parameter of the audio script"
      ],
      "metadata": {
        "id": "LdDDeEJUMk3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe(\"audio4.mp4\", generate_kwargs={\"language\": \"kannada\"})\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ty78vMmMDit",
        "outputId": "9a6c986d-c89a-4c12-d415-f8cba9914d5f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ‡≤Æ‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤® ‡≤ï‡≤§‡≥Ü‡≤Ø‡≤æ ‡≤π‡≥á‡≤≥‡≤ø‡≤§‡≥Å ‡≤á‡≤¶‡≥Å ‡≤¨‡≤Ç‡≤¨‡≥Ü ‡≤Ü ‡≤ï‡≤§‡≥Ü‡≤Ø‡≤≤‡≥ç‡≤≤‡≤ø‡≤¶‡≥ç‡≤¶ ‡≤∞‡≤æ‡≤ú‡≤®‡≤Ç‡≤ó‡≥Ü ‡≤®‡≤ø‡≤®‡≥Å ‡≤¨‡≤Ç‡≤¶‡≥Ü ‡≤Ø‡≥ã‡≤ó‡≤µ‡≥Å ‡≤í‡≤Æ‡≥ç‡≤Æ‡≥Ü ‡≤¨‡≤∞‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å ‡≤®‡≤Æ‡≤ó‡≥Ü ‡≤Ø‡≥ã‡≤ó‡≥ç‡≤Ø‡≤§‡≥Ü ‡≤í‡≤Ç‡≤¶‡≥Ü ‡≤â‡≤≥‡≤ø ‡≤¨‡≥Å‡≤¶‡≥Å ‡≤ï‡≤®‡≥Ü‡≤Ø‡≥Ü ‡≤∏‡≥Ç‡≤∞‡≤ø‡≤Ø‡≤®‡≥Å ‡≤¨‡≤æ ‡≤ö‡≤Ç‡≤¶‡≥ç‡≤∞‡≤®‡≥Å ‡≤¨‡≤æ ‡≤∞‡≤æ‡≤ú‡≤®‡≥Å ‡≤í‡≤™‡≥ç‡≤™‡≤æ ‡≤á‡≤∞‡≤æ‡≤ú‡≤®‡≥Å ‡≤í‡≤™‡≥ç‡≤™‡≤æ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe(\"audio5.mp4\", generate_kwargs={\"language\": \"hindi\"})\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-Jl-msZFzOF",
        "outputId": "3b50c8cc-8188-41c0-ad19-6f1fd0eb1ba7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ‡§§‡•Ç ‡§π‡•Ä ‡§§‡•ã ‡§ú‡§®‡•ç‡§®‡§§ ‡§Æ‡•á‡§∞‡•Ä, ‡§§‡•Ç ‡§π‡•Ä ‡§Æ‡•á‡§∞‡§æ ‡§ú‡•Å‡§®‡•Ç, ‡§§‡•Ç ‡§π‡•Ä ‡§§‡•ã ‡§Æ‡§®‡•ç‡§®‡§§ ‡§Æ‡•á‡§∞‡•Ä, ‡§§‡•Ç ‡§π‡•Ä ‡§∞‡•Å‡§π ‡§ï‡§æ ‡§∏‡•Å‡§ï‡•Ç‡§Æ, ‡§§‡•Ç ‡§π‡•Ä ‡§Ö‡§ñ‡•ç‡§ñ‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§†‡§Ç‡§°‡§ï, ‡§§‡•Ç ‡§π‡•Ä ‡§¶‡§ø‡§≤ ‡§ï‡•Ä ‡§π‡•à ‡§¶‡§∏‡•ç‡§§‡§ï, ‡§î‡§∞ ‡§ï‡•Å‡§õ ‡§®‡§æ ‡§ú‡§æ‡§®‡•Ç, ‡§Æ‡•à‡§Ç ‡§¨‡§∏ ‡§á‡§§‡§®‡§æ ‡§π‡•Ä ‡§ú‡§æ‡§®‡•Ç, ‡§§‡•Å‡§ù ‡§Æ‡•á‡§Ç ‡§∞‡§¨ ‡§¶‡§ø‡§ñ‡§§‡§æ ‡§π‡•à, ‡§Ø‡§æ‡§∞‡§æ ‡§Æ‡•à‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§∞‡•Ç‡§Å\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, Whisper performs the task of speech transcription, where the source audio language is the same as the target text language. To perform speech translation, where the target text is in English, set the task to \"translate\":"
      ],
      "metadata": {
        "id": "cg-undNYJ_MJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Audio5.mp4 was a Hindi audio file it translates to English"
      ],
      "metadata": {
        "id": "QB70pgDNNGtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe(\"audio5.mp4\", generate_kwargs={\"task\": \"translate\"})\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKVT0ccVKBC_",
        "outputId": "780043ad-32c4-40b7-e694-bf9872339438"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " You are my heaven, You are my passion You are my prayer, You are my peace You are the coolness of my eyes, You are the key of my heart I don't know anything else, I just know this much You have God in you, what can I do?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " For sentence-level timestamps, pass the return_timestamps argument:"
      ],
      "metadata": {
        "id": "Pel9orVCOFKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe(\"audio6.mp4\", return_timestamps=True) #Conversation between Lex Friedman and Elon Musk\n",
        "print(result[\"chunks\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Xd-Rs9lNCWe",
        "outputId": "fb5bd15f-83f9-441a-e706-60c1a9f2500a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'timestamp': (0.0, 3.68), 'text': ' If we think about young people in high school, maybe in college,'}, {'timestamp': (3.68, 8.64), 'text': ' what advice would you give to them about if they want to try to do something big in this world,'}, {'timestamp': (8.64, 12.08), 'text': ' they want to really have a big positive impact, what advice would you give them?'}, {'timestamp': (12.08, 16.56), 'text': ' Try to be useful. Do things that are useful to your fellow human beings,'}, {'timestamp': (16.56, 23.6), 'text': \" to the world. It's very hard to be useful. Very hard. Are you contributing more than you consume?\"}, {'timestamp': (26.28, 31.78), 'text': \" Very hard. You know, are you contributing more than you consume? You know, like, try to have a positive net contribution to society. I think that's the thing to aim for. You know,\"}, {'timestamp': (31.78, 36.36), 'text': ' not to try to be sort of a leader for the sake of being a leader or whatever. A lot'}, {'timestamp': (36.36, 41.5), 'text': \" of time people who, a lot of times the people you want as leaders are the people who don't\"}, {'timestamp': (41.5, 43.46), 'text': ' want to be leaders.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe(\"audio5.mp4\", return_timestamps=True, generate_kwargs={\"language\": \"hindi\", \"task\": \"translate\"})\n",
        "print(result[\"chunks\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGezX8V0ONDV",
        "outputId": "3031fce0-48a9-42bf-db98-67a7e16b64ee"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'timestamp': (0.0, 5.0), 'text': ' You are my heaven, You are my passion'}, {'timestamp': (5.0, 11.0), 'text': \" You are my prayer, You are my soul's peace\"}, {'timestamp': (11.0, 17.0), 'text': ' You are the coolness of my eyes, You are the key of my heart'}, {'timestamp': (17.0, 23.0), 'text': \" I don't know anything else, I just know this much\"}, {'timestamp': (23.0, 29.0), 'text': ' You see God in you, what can I do?'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fSqoNYpiOkQ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}